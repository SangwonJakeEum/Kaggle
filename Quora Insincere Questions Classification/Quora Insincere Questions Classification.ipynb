{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## General Description\n",
    "In this competition you will be predicting whether a question asked on Quora is sincere or not.\n",
    "\n",
    "An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:\n",
    "\n",
    "Has a non-neutral tone\n",
    "Has an exaggerated tone to underscore a point about a group of people\n",
    "Is rhetorical and meant to imply a statement about a group of people\n",
    "Is disparaging or inflammatory\n",
    "Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype\n",
    "Makes disparaging attacks/insults against a specific person or group of people\n",
    "Based on an outlandish premise about a group of people\n",
    "Disparages against a characteristic that is not fixable and not measurable\n",
    "Isn't grounded in reality\n",
    "Based on false information, or contains absurd assumptions\n",
    "Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers\n",
    "The training data includes the question that was asked, and whether it was identified as insincere (target = 1). The ground-truth labels contain some amount of noise: they are not guaranteed to be perfect.\n",
    "\n",
    "Note that the distribution of questions in the dataset should not be taken to be representative of the distribution of questions asked on Quora. This is, in part, because of the combination of sampling procedures and sanitization measures that have been applied to the final dataset.\n",
    "\n",
    "File descriptions\n",
    "train.csv - the training set\n",
    "test.csv - the test set\n",
    "sample_submission.csv - A sample submission in the correct format\n",
    "enbeddings/ - (see below)\n",
    "Data fields\n",
    "qid - unique question identifier\n",
    "question_text - Quora question text\n",
    "target - a question labeled \"insincere\" has a value of 1, otherwise 0\n",
    "This is a Kernels-only competition. The files in this Data section are downloadable for reference in Stage 1. Stage 2 files will only be available in Kernels and not available for download.\n",
    "\n",
    "What will be available in the 2nd stage of the competition?\n",
    "In the second stage of the competition, we will re-run your selected Kernels. The following files will be swapped with new data:\n",
    "\n",
    "test.csv - This will be swapped with the complete public and private test dataset. This file will have ~56k rows in stage 1 and ~376k rows in stage 2. The public leaderboard data remains the same for both versions. The file name will be the same (both test.csv) to ensure that your code will run.\n",
    "sample_submission.csv - similar to test.csv, this will be changed from ~56k in stage 1 to ~376k rows in stage 2 . The file name will remain the same.\n",
    "Embeddings\n",
    "External data sources are not allowed for this competition. We are, though, providing a number of word embeddings along with the dataset that can be used in the models. These are as follows:\n",
    "\n",
    "GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n",
    "glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n",
    "paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n",
    "wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/0f/5157e6b153b3d4a70dc5fbe2ab6f209604197590f387f03177b7a249ac60/lightgbm-2.2.3-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 9.9MB/s eta 0:00:01    57% |██████████████████▎             | 675kB 18.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/jake/anaconda3/envs/tf/lib/python3.6/site-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/jake/anaconda3/envs/tf/lib/python3.6/site-packages (from lightgbm) (1.15.4)\n",
      "Requirement already satisfied: scikit-learn in /home/jake/anaconda3/envs/tf/lib/python3.6/site-packages (from lightgbm) (0.20.2)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jake/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/Quora/train.csv\")\n",
    "test = pd.read_csv(\"../input/Quora/train.csv\")\n",
    "print(\"Train shape : \", train_df.shape)\n",
    "print(\"Test shape : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faca00ffdd8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Target Distribution:\n",
    "\n",
    "First let us look at the distribution of the target variable to understand more about the imbalance and so on.\n",
    "타겟의 분포가 어떻게 되는지 알아보자 \n",
    "'''\n",
    "sns.countplot(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "blue"
         },
         "orientation": "h",
         "showlegend": false,
         "type": "bar",
         "uid": "284391e8-e90c-49dd-8a53-012b1ea52799",
         "x": [
          9938,
          10063,
          10148,
          10524,
          10533,
          10562,
          10709,
          10958,
          11090,
          11184,
          11507,
          11653,
          11940,
          11998,
          12026,
          12028,
          12071,
          12146,
          12238,
          12501,
          12552,
          12857,
          12996,
          13319,
          13368,
          14260,
          15089,
          15140,
          15536,
          15545,
          15781,
          15941,
          15985,
          16508,
          16743,
          17118,
          18073,
          19250,
          19728,
          20108,
          20788,
          21641,
          25696,
          28840,
          34827,
          37618,
          37960,
          57105,
          58731,
          60816
         ],
         "xaxis": "x",
         "y": [
          "indian",
          "long",
          "really",
          "us",
          "learn",
          "year",
          "still",
          "job",
          "different",
          "first",
          "start",
          "india",
          "used",
          "difference",
          "person",
          "need",
          "i'm",
          "life",
          "it?",
          "better",
          "possible",
          "go",
          "what's",
          "work",
          "new",
          "feel",
          "time",
          "could",
          "india?",
          "without",
          "become",
          "want",
          "ever",
          "find",
          "take",
          "know",
          "way",
          "use",
          "someone",
          "much",
          "many",
          "think",
          "make",
          "one",
          "good",
          "like",
          "people",
          "would",
          "get",
          "best"
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "blue"
         },
         "orientation": "h",
         "showlegend": false,
         "type": "bar",
         "uid": "8200ddf9-5a3e-47bf-b496-5cf6072118db",
         "x": [
          1090,
          1106,
          1119,
          1150,
          1167,
          1179,
          1218,
          1243,
          1246,
          1255,
          1259,
          1321,
          1360,
          1382,
          1461,
          1483,
          1495,
          1497,
          1515,
          1537,
          1572,
          1588,
          1618,
          1639,
          1776,
          1834,
          1887,
          1937,
          2043,
          2048,
          2122,
          2123,
          2171,
          2298,
          2343,
          2478,
          2549,
          2672,
          2828,
          2984,
          3152,
          3177,
          3351,
          3552,
          3774,
          4126,
          4757,
          4893,
          5708,
          11036
         ],
         "xaxis": "x2",
         "y": [
          "since",
          "become",
          "country",
          "democrats",
          "take",
          "ever",
          "always",
          "president",
          "can't",
          "people?",
          "good",
          "true",
          "still",
          "say",
          "really",
          "world",
          "believe",
          "donald",
          "know",
          "much",
          "feel",
          "one",
          "american",
          "muslim",
          "even",
          "chinese",
          "liberals",
          "make",
          "india",
          "sex",
          "indians",
          "girls",
          "hate",
          "us",
          "want",
          "americans",
          "quora",
          "black",
          "muslims",
          "indian",
          "men",
          "get",
          "white",
          "many",
          "think",
          "would",
          "women",
          "trump",
          "like",
          "people"
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Frequent words of sincere questions",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Frequent words of insincere questions",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 1200,
        "paper_bgcolor": "rgb(233,233,233)",
        "title": {
         "text": "Word Count Plots"
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div id=\"bd4651df-dbee-4b41-ba77-04d116b6a44a\" style=\"height: 1200px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bd4651df-dbee-4b41-ba77-04d116b6a44a\", [{\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [9938, 10063, 10148, 10524, 10533, 10562, 10709, 10958, 11090, 11184, 11507, 11653, 11940, 11998, 12026, 12028, 12071, 12146, 12238, 12501, 12552, 12857, 12996, 13319, 13368, 14260, 15089, 15140, 15536, 15545, 15781, 15941, 15985, 16508, 16743, 17118, 18073, 19250, 19728, 20108, 20788, 21641, 25696, 28840, 34827, 37618, 37960, 57105, 58731, 60816], \"y\": [\"indian\", \"long\", \"really\", \"us\", \"learn\", \"year\", \"still\", \"job\", \"different\", \"first\", \"start\", \"india\", \"used\", \"difference\", \"person\", \"need\", \"i'm\", \"life\", \"it?\", \"better\", \"possible\", \"go\", \"what's\", \"work\", \"new\", \"feel\", \"time\", \"could\", \"india?\", \"without\", \"become\", \"want\", \"ever\", \"find\", \"take\", \"know\", \"way\", \"use\", \"someone\", \"much\", \"many\", \"think\", \"make\", \"one\", \"good\", \"like\", \"people\", \"would\", \"get\", \"best\"], \"type\": \"bar\", \"uid\": \"284391e8-e90c-49dd-8a53-012b1ea52799\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [1090, 1106, 1119, 1150, 1167, 1179, 1218, 1243, 1246, 1255, 1259, 1321, 1360, 1382, 1461, 1483, 1495, 1497, 1515, 1537, 1572, 1588, 1618, 1639, 1776, 1834, 1887, 1937, 2043, 2048, 2122, 2123, 2171, 2298, 2343, 2478, 2549, 2672, 2828, 2984, 3152, 3177, 3351, 3552, 3774, 4126, 4757, 4893, 5708, 11036], \"y\": [\"since\", \"become\", \"country\", \"democrats\", \"take\", \"ever\", \"always\", \"president\", \"can't\", \"people?\", \"good\", \"true\", \"still\", \"say\", \"really\", \"world\", \"believe\", \"donald\", \"know\", \"much\", \"feel\", \"one\", \"american\", \"muslim\", \"even\", \"chinese\", \"liberals\", \"make\", \"india\", \"sex\", \"indians\", \"girls\", \"hate\", \"us\", \"want\", \"americans\", \"quora\", \"black\", \"muslims\", \"indian\", \"men\", \"get\", \"white\", \"many\", \"think\", \"would\", \"women\", \"trump\", \"like\", \"people\"], \"type\": \"bar\", \"uid\": \"8200ddf9-5a3e-47bf-b496-5cf6072118db\", \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of sincere questions\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of insincere questions\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"height\": 1200, \"width\": 900, \"paper_bgcolor\": \"rgb(233,233,233)\", \"title\": {\"text\": \"Word Count Plots\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"bd4651df-dbee-4b41-ba77-04d116b6a44a\" style=\"height: 1200px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bd4651df-dbee-4b41-ba77-04d116b6a44a\", [{\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [9938, 10063, 10148, 10524, 10533, 10562, 10709, 10958, 11090, 11184, 11507, 11653, 11940, 11998, 12026, 12028, 12071, 12146, 12238, 12501, 12552, 12857, 12996, 13319, 13368, 14260, 15089, 15140, 15536, 15545, 15781, 15941, 15985, 16508, 16743, 17118, 18073, 19250, 19728, 20108, 20788, 21641, 25696, 28840, 34827, 37618, 37960, 57105, 58731, 60816], \"y\": [\"indian\", \"long\", \"really\", \"us\", \"learn\", \"year\", \"still\", \"job\", \"different\", \"first\", \"start\", \"india\", \"used\", \"difference\", \"person\", \"need\", \"i'm\", \"life\", \"it?\", \"better\", \"possible\", \"go\", \"what's\", \"work\", \"new\", \"feel\", \"time\", \"could\", \"india?\", \"without\", \"become\", \"want\", \"ever\", \"find\", \"take\", \"know\", \"way\", \"use\", \"someone\", \"much\", \"many\", \"think\", \"make\", \"one\", \"good\", \"like\", \"people\", \"would\", \"get\", \"best\"], \"type\": \"bar\", \"uid\": \"284391e8-e90c-49dd-8a53-012b1ea52799\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [1090, 1106, 1119, 1150, 1167, 1179, 1218, 1243, 1246, 1255, 1259, 1321, 1360, 1382, 1461, 1483, 1495, 1497, 1515, 1537, 1572, 1588, 1618, 1639, 1776, 1834, 1887, 1937, 2043, 2048, 2122, 2123, 2171, 2298, 2343, 2478, 2549, 2672, 2828, 2984, 3152, 3177, 3351, 3552, 3774, 4126, 4757, 4893, 5708, 11036], \"y\": [\"since\", \"become\", \"country\", \"democrats\", \"take\", \"ever\", \"always\", \"president\", \"can't\", \"people?\", \"good\", \"true\", \"still\", \"say\", \"really\", \"world\", \"believe\", \"donald\", \"know\", \"much\", \"feel\", \"one\", \"american\", \"muslim\", \"even\", \"chinese\", \"liberals\", \"make\", \"india\", \"sex\", \"indians\", \"girls\", \"hate\", \"us\", \"want\", \"americans\", \"quora\", \"black\", \"muslims\", \"indian\", \"men\", \"get\", \"white\", \"many\", \"think\", \"would\", \"women\", \"trump\", \"like\", \"people\"], \"type\": \"bar\", \"uid\": \"8200ddf9-5a3e-47bf-b496-5cf6072118db\", \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of sincere questions\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of insincere questions\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"height\": 1200, \"width\": 900, \"paper_bgcolor\": \"rgb(233,233,233)\", \"title\": {\"text\": \"Word Count Plots\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Word Frequency plot of sincere & insincere questions:**\n",
    "'''\n",
    "각각의 데이터에서 단어의 분포가 어떻게 되는지 \n",
    "'''\n",
    "from collections import defaultdict\n",
    "train1_df = train_df[train_df[\"target\"]==1]\n",
    "train0_df = train_df[train_df[\"target\"]==0]\n",
    "\n",
    "## custom function for ngram generation ##\n",
    "def generate_ngrams(text, n_gram=1):\n",
    "    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n",
    "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "## custom function for horizontal bar chart ##\n",
    "\n",
    "def horizontal_bar_chart(df, color):\n",
    "    trace = go.Bar(\n",
    "        y=df[\"word\"].values[::-1],\n",
    "        x=df[\"wordcount\"].values[::-1],\n",
    "        showlegend=False,\n",
    "        orientation = 'h',\n",
    "        marker=dict(\n",
    "            color=color,\n",
    "        ),\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "    return trace\n",
    "## Get the bar chart from sincere questions ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in train0_df[\"question_text\"]:\n",
    "    for word in generate_ngrams(sent):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace0 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n",
    "\n",
    "## Get the bar chart from insincere questions ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in train1_df[\"question_text\"]:\n",
    "    for word in generate_ngrams(sent):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace1 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,\n",
    "                          subplot_titles=[\"Frequent words of sincere questions\", \n",
    "                                          \"Frequent words of insincere questions\"])\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 2)\n",
    "fig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
    "py.iplot(fig, filename='word-plots')\n",
    "\n",
    "#plt.figure(figsize=(10,16))\n",
    "#sns.barplot(x=\"ngram_count\", y=\"ngram\", data=fd_sorted.loc[:50,:], color=\"b\")\n",
    "#plt.title(\"Frequent words for Insincere Questions\", fontsize=16)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz\n",
      "Building wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jake/.cache/pip/wheels/b6/68/c3/a05a35f647ba871e5572b9bbfc0b95fd1c6637a2219f959e7a\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
